---
title: "p8105_hw2_xh2601"
author: "Samantha Xinwei Han"
date: "2025-09-29"
output: github_document
---

```{r setup, message = FALSE}
# load the tidyverse and readxl library
library(tidyverse)
library(readxl)
```

## Problem 1

#### Step One. Clean the data in pols-month.csv
1. Use separate() to break up the variable mon into integer variables year, month, and day

```{r}
# create a dataframe named "pols" for pols-month.csv data
# use 'clean_names()' to clean variable names
# use 'separate()' to break "mon" variable into "year", "month", "day" variables, separated by "-"
# use 'mutate()' to convert character variables into integer variables
pols = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  )
```

2. Replace month number with month name

```{r}
# use 'mutate()' to replace month number with month name in "month"
pols = mutate(
  pols,
  month = case_match(
    month,
    1 ~ "January",
    2 ~ "February",
    3 ~ "March",
    4 ~ "April",
    5 ~ "May",
    6 ~ "June",
    7 ~ "July",
    8 ~ "August",
    9 ~ "September",
    10 ~ "October",
    11 ~ "November",
    12 ~ "December"
  )
)
```

3. Create a president variable taking values gop and dem, and remove prez_dem and prez_gop

```{r}
# use 'mutate()' to create "president" variable, so that if "prez_gop" is 1, "president" is "gop", and if "prez_dem" is 1, "president" is "dem"
# use 'select()' to remove "prez_dem" and "prez_gop"
# use 'select()' to reorder the dataframe, so that "president" is in the front
pols = pols |> 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) |> 
  select(-prez_dem, -prez_gop) |> 
  select(year, month, day, president, everything())
```

4. Remove the day variable

```{r}
# use 'select()' to remove "day"
pols = select(pols, -day)
```

#### Step Two. Clean the data in snp.csv

```{r}
# create a dataframe named "snp" for snp.csv data
# use 'clean_names()' to clean variable names
# use 'separate()' to break "date" variable into "year", "month", "day" variables, separated by "/"
# use 'mutate()' to convert character variables into integer variables
# use 'mutate()' to replace month number with month name in "month"
# use 'mutate()' to replace year number with the full year
# use 'select()' to remove "day"
# use 'select()' to reorder the dataframe, so that "year" and "month" are the leading cols
snp = 
  read_csv("data/fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) |> 
  mutate(
    month = case_match(
      month,
      1 ~ "January",
      2 ~ "February",
      3 ~ "March",
      4 ~ "April",
      5 ~ "May",
      6 ~ "June",
      7 ~ "July",
      8 ~ "August",
      9 ~ "September",
      10 ~ "October",
      11 ~ "November",
      12 ~ "December"
    )
  ) |> 
  mutate(
    year = if_else(year < 25, year + 2000, year + 1900)
  ) |> 
  select(-day) |> 
  select(year, month, everything())
```

#### Step Three. Tidy the unemployment data

```{r}
# create a dataframe named "unemployment" for unemployment.csv data
# use 'clean_names()' to clean variable names
# use 'pivot_longer()' to convert wide to long format
# use 'mutate()' to convert character variable into integer variable in "year"
# use 'mutate()' to replace abbreviated month with month name in "month"
unemployment = 
  read_csv("data/fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment_percentage"
  ) |> 
  mutate(
    year = as.integer(year)
  ) |> 
  mutate(
    month = case_match(
      month,
      "jan" ~ "January",
      "feb" ~ "February",
      "mar" ~ "March",
      "apr" ~ "April",
      "may" ~ "May",
      "jun" ~ "June",
      "jul" ~ "July",
      "aug" ~ "August",
      "sep" ~ "September",
      "oct" ~ "October",
      "nov" ~ "November",
      "dec" ~ "December"
    )
  )
```

#### Step Four. Join the datasets and interpret

```{r}
# use 'left_join()' to merge snp into pols
# use 'left_join()' to merge unemployment into the previous result
pol_econ_df = 
  left_join(pols, snp, by = c("year", "month")) |> 
  left_join(unemployment, by = c("year", "month"))
```

**Interpretation:**

*pols*: contains 822 observations of 9 variables related to the number of politicians who are democratic or republican at a given time. 

- "year" and "month" record the year and month of the count; 
- "president" indicate whether the president was republican or democratic on the associated year and month (gop = republican, dem = democratic); 
- "gov_gop", "sen_gop", and "rep_gop" record the number of republican governors, senators, and representatives, respectively, on the associated year and month;
- "gov_dem", "sen_dem", and "rep_dem" record the number of democratic governors, senators, and representatives, respectively, on the associated year and month.

*snp*: contains 787 observations of 3 variables related to Standard & Poorâ€™s stock market index (S&P), often used as a representative measure of stock market as a whole, at a given time.

- "year" and "month" record the year and month of the observation;
- "close" records the closing values of the S&P stock index on the associated year and month.

*unemployment*: contains 816 observations of 3 variables related to the percentage of unemployment at a given time.

- "year" and "month" record the year and month of the measurement;
- "unemployment_percentage" records the percentage of unemployment on the associated year and month.

*pol_econ_df*: contains 822 observations of 11 variables combining variables from *pols*, *snp*, and *unemployment* datasets.

- dimension: 822 rows, 11 columns.
- range of years: from January 1947 to June 2015. This range is determined by the *pols* dataset, while variables from *snp* and *unemployment* are included only for months and years where their data overlap with this time period.
- names of key variables: 
  - "year" and "month" record the year and month of the observation, which are form the common time index across all three datasets.
  - Each observation could include the party of the president, the number of Democratic and Republican politicians, S&P index, and unemployment rate, provided that valid data are available from the three source datasets for that year and month.
- *pol_econ_df* is a monthly dataset spanning January 1947 to June 2015, containing political and economic related data. It allows us to learn the relations between political power (specifically, the party holding presidency and party composition of politicians) and economic indicators including stock market performance (S&P index) and the unemployment rate.

## Problem 2

#### Step One. Clean the Mr. Trash Wheel sheet

```{r}
# use 'read_excel()' to read the file
# use 'sheet' to specify the sheet 
# use 'skip' to omit non-data entries - top row
# use 'range' to omit non-data entries - columns after the 14th column
# use 'clean_names()' to clean variable names
# use 'rename()' to rename weight and volume variable names for clarity
# use 'drop_na()' to omit rows that do not include dumpster-specific data
# use 'mutate()' to round the number of sports balls to the nearest integer
# use 'mutate()' to convert the previous result to an integer
# use 'mutate()' to convert year to an integer
# use 'mutate()' to create a variable to keep track of which Trash Wheel is which 
mr_tw_df = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    skip = 1,
    range = cell_cols(1:14)) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, volume = volume_cubic_yards) |> 
  drop_na(dumpster) |> 
  mutate(sports_balls = round(sports_balls)) |> 
  mutate(sports_balls = as.integer(sports_balls)) |> 
  mutate(year = as.integer(year)) |> 
  mutate(trash_wheel_type = "mr_trash_wheel")
```

#### Step Two. Clean the Professor Trash Wheel sheet

```{r}
prof_tw_df = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    skip = 1,
    range = cell_cols(1:13)) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, volume = volume_cubic_yards) |> 
  drop_na(dumpster) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel_type = "professor_trash_wheel")
```

#### Step Three. Clean the Gwynnda Trash Wheel sheet

```{r}
gwyn_tw_df = 
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    skip = 1,
    range = cell_cols(1:12)) |> 
  janitor::clean_names() |> 
  rename(weight = weight_tons, volume = volume_cubic_yards) |> 
  drop_na(dumpster) |> 
  mutate(year = as.integer(year)) |>
  mutate(trash_wheel_type = "gwynnda_trash_wheel") 
```

#### Step Four. Combine the three Trash Wheel sheets

```{r}
# use 'bind_rows()' to combine three datasets
# use 'select()' to reorder the dataframe, so that "trash_wheel_type" is in the front
combined_tw_df = 
  bind_rows(mr_tw_df, prof_tw_df, gwyn_tw_df) |> 
  select(dumpster, trash_wheel_type, year, everything())
```

#### Step Five. Interpret data

```{r}
# total weight of trash collected by Professor Trash Wheel
wt_prof_tw = sum(mr_tw_df[["weight"]], na.rm = TRUE)
  
# total number of cigarette butts collected by Gwynnda in June of 2022
cig_2206_gwyn_tw = gwyn_tw_df |> 
  filter(year == 2022, month == "June") |> 
  pull(cigarette_butts) |> 
  sum(na.rm = TRUE)
```

**Interpretation:**

- There are 1033 observations and 15 columns in the combined dataset (*combined_tw_df*), including 651 observations from the Mr. Trash Wheel dataset (*mr_tw_df*), 119 observations from the Professor Trash Wheel dataset (*prof_tw_df*), and 263 observations from the Gwynnda Trash Wheel dataset (*gwyn_tw_df*).

- *mr_tw_df* contains 15 columns: dumpster ID; year, month, and date of observation; total weight (in tons) and volume (in cubic yards) of trash on the observation date and dumpster id; numbers of plastic bottles, polystyrene, cigarette butts, glass bottles, plastic bags, wrappers, and sports balls on the observation date and dumpster id; estimated number of homes that could have been powered by the collected trash; and the type/name of trash wheel.

- *prof_tw_df* contains 14 columns similar to *mr_tw_df*, but without the number of sports balls. 

- *gwyn_tw_df* contains 13 columns similar to *mr_tw_df*, but without the number of sports balls or glass bottles. 

- The total weight of trash collected by Professor Trash Wheel is `r wt_prof_tw` tons.

- The total number of cigarette butts collected by Gwynnda in June of 2022 is `r format(cig_2206_gwyn_tw, scientific = FALSE)`.

## Problem 3

#### Step One. Clean zip codes data

```{r}
# create a dataframe named "zip_code_df" for Zip Codes.csv data
# use 'clean_names()' to clean variable names
# use 'mutate()' to make sure FIPS and zip code variables are integer variables
# use 'select()' to reorder the dataframe, so that the date and state information are leading, then county info, then neighborhood info
# use 'rename()' to rename file_date for clarity when combining
zip_code_df = 
  read_csv("data/zillow_data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(
    state_fips = as.integer(state_fips),
    county_fips = as.integer(county_fips),
    zip_code = as.integer(zip_code)
  ) |> 
  select(file_date, state_fips, county, county_code, county_fips, zip_code, neighborhood) |> 
  rename(zip_code_date = file_date)
```


#### Step Two. Clean ZORI data


#### Step Three. Combine and interpret

Briefly describe the resulting tidy dataset. 
How many total observations exist? 
How many unique ZIP codes are included, and how many unique neighborhoods?

Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. 
Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021. 






